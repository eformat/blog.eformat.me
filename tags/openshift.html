<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    
    <title>eformat.me - openshift</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="eformat.me : openshift">
    <meta property="og:title" content="eformat.me - openshift" />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://blog.eformat.me/img/eformat.me.jpg" />
    <meta property="og:url" content="https://blog.eformat.me/tags/openshift.html" />
    <meta property="og:description" content="eformat.me : openshift" />
    <meta property="og:locale" content="en_GB" />
    <meta property="og:site_name" content="eformat.me" />

    <!-- Le styles -->
    <link href="../css/lightbox.css" rel="stylesheet">
    <link href="../css/yeti/bootstrap.min.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link href="../css/asciidoctor.css" rel="stylesheet">
    <!-- link href="/css/bootstrap-theme.min.css" rel="stylesheet" -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
    <link rel="shortcut icon" href="../favicon.ico">

    <!-- WebAnalytics -->
    <script defer data-domain="blog.eformat.me" src="https://plausible.apps.sno.eformat.me/js/script.js"></script>
  </head>
  <body>
    <div id="wrap">

	
	      <!-- Fixed navbar -->
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
        <div class="container-fluid">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-menu">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../index.html">eformat.me</a>
          </div>
          <div class="collapse navbar-collapse" id="navbar-menu">
            <ul class="nav navbar-nav">
              <li><a href="https://github.com/eformat" target="github:eformat">Github</a></li>
              <li><a href="../archive.html">Archives</a></li>
              <li><a href="../feeds/posts/default.xml">Flux RSS</a></li>
            </ul>
          </div><!--/.nav-collapse -->
        </div>
      </div>
      <div class="container">


	<div class="page-header">
            <div class="row">
                <div class="col-xs-4 col-md-2"><img src="../img/eformat.me.jpg"></div>
                <div class="col-xs-12 col-md-8"><h1>Tag: openshift</h1></div>
            </div>
	</div>

    <div class="row">

    <div class="col-sm-8">
        
            
                <a href="../2023/04/disconnected-registries.html"><h1>OpenShift Install, Semi-Connected Registries and Mirror by Digest Images</h1></a>
                <p>12 April 2023</p>

                <p>Tags :
                <a href="openshift.html">openshift</a>, <a href="gitops.html">gitops</a>, <a href="registries.html">registries</a>, <a href="disconnected.html">disconnected</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2023/04/disconnected-registries.html" data-text="OpenShift Install, Semi-Connected Registries and Mirror by Digest Images" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2023/04/disconnected-registries.html"></div>

                <p><div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>I have been working with disconnected OpenShift clusters quite a lot recently. One of the things you need to deal with is disconnected registries and mirror by digest images.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_quay_transparent_proxy_pull_through_cache">Quay Transparent Proxy-Pull Through Cache</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There are a couple general approaches to configuring registries when disconnected. The <a href="https://docs.openshift.com/container-platform/4.12/installing/disconnected_install/index.html">product documentation</a> has great depth of detail about using a Quay Mirror Registry. This is the right approach when wanting disconnected. The downside when you are testing things out in a lab is the mirror import process is both time-consuming and uses a lot of disk space.</p>
</div>
<div class="paragraph">
<p>One approach i have become fond of is a what i call a <code>semi-connected</code> method, where your clusters' use a <a href="https://www.youtube.com/watch?v=oVlRDuCD6ic">Quay Transparent Proxy-Pull Through Cache</a> to speed things up. This still uses disk space, but you don&#8217;t need to import all the images before installing a cluster.</p>
</div>
<div class="paragraph">
<p>After you install the quay mirror registry on the provisioning host, set this in your <code>config.yaml</code> and restart the quay pods or service:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">FEATURE_PROXY_CACHE: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>This setup mimics what you would need to do when disconnected i.e. we always pull from the mirror registry when installing - but it is quicker to test as the mirror registry is connected. When configuring the OpenShift install method, the pull secret i use is <strong>just</strong> to the mirror. More on that below.</p>
</div>
<div class="paragraph">
<p>If you also set the cache timeout for your Organisations to be months or even years! then your images will hang around for a long time.</p>
</div>
<div class="paragraph">
<p>For installing OpenShift, you really need (at a minimum) two mirror organisations. I set up these two (admin is a default):</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="quay-mirror-orgs">
  <img src="/2023/04/quay-mirror-orgs.png" class="zoom">
</div>
<div class="paragraph">
<p>Where each Organisation points to these registries:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">registry-redhat-io -&gt; registry.redhat.io
ocp4-mirror -&gt; quay.io/openshift-release-dev</code></pre>
</div>
</div>
<div class="paragraph">
<p>One nice trick is that you can <strong>base64 decode</strong> your Red Hat <strong>pull-secret</strong> (you download this from cloud.redhat.com) and use those credentials in the Organisation mirror registry setup for authentication.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ocp_install_configuration">OCP Install Configuration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now comes for the tricky part - configuring your OpenShift installer setup. There are a several ways to do this. The one you use depends on your install method and how you wish to control the <strong>registries.conf</strong> that gets configured for you cluster nodes.</p>
</div>
<div class="paragraph">
<p>I have been working with the <strong>Agent-based</strong> installer method for Bare Metal (i fake it on libvirt with sushy) - you can <a href="https://github.com/eformat/acm-gitops-ocp">check out all the code here</a>.</p>
</div>
<div class="paragraph">
<p>The issue i think everyone quickly discovers is that the OpenShift installer sets all mirror&#8217;s by digest to be true i.e. <strong>mirror-by-digest-only = true</strong>. If you check the <a href="https://github.com/openshift/installer">installer code</a> its here:</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="ocp-installer-boostrap">
  <img src="/2023/04/ocp-installer-boostrap.png" class="zoom">
</div>
<div class="paragraph">
<p>Setting mirror by digest to true is intentional, it helps stop image spoofing or getting an image from a moving tag.</p>
</div>
<div class="paragraph">
<p>Unfortunately not all Operators pull by digest either. In fact the deployments that are part of the <strong>openshift-marketplace</strong> do not. So after a cluster install we see Image Pull errors like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc get pods -n openshift-marketplace
NAME                                   READY   STATUS             RESTARTS      AGE
certified-operators-d2nd9              0/1     ImagePullBackOff   0             15h
certified-operators-pqrlz              0/1     ImagePullBackOff   0             15h
community-operators-7kpbm              0/1     ImagePullBackOff   0             15h
community-operators-k662l              0/1     ImagePullBackOff   0             15h
marketplace-operator-84457bfc9-v22db   1/1     Running            4 (15h ago)   16h
redhat-marketplace-kjrt9               0/1     ImagePullBackOff   0             15h
redhat-marketplace-sqch2               0/1     ImagePullBackOff   0             15h
redhat-operators-4m4gt                 0/1     ImagePullBackOff   0             15h
redhat-operators-62z6x                 0/1     ImagePullBackOff   0             15h</code></pre>
</div>
</div>
<div class="paragraph">
<p>And checking one of the pods we see it is trying to pull by tag:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc describe pod certified-operators-d2nd9
Normal  BackOff  2m2s (x4179 over 15h)  kubelet  Back-off pulling image "registry.redhat.io/redhat/certified-operator-index:v4.12"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Unfortunately you cannot configure <strong>ImageContentSourcePolicy</strong> for <strong>mirror-by-digest-only = false</strong> so (currently) the only solution is to apply MachineConfig <strong>post</strong> your install as a day#2 thing as documented in this <a href="https://access.redhat.com/solutions/4817401">Knowledge Base Article</a></p>
</div>
<div class="paragraph">
<p>Hopefully in an upcoming OpenShift relaease (4.13 or 4.14) we will be able to use the <strong>new API&#8217;s for CRDs ImageDigestMirrorSet ImageTagMirrorSet</strong> - see <a href="https://issues.redhat.com/browse/OCPNODE-521">Allow mirroring images by tags</a> RFE for more details on these changes.</p>
</div>
<div class="paragraph">
<p>For now though, i use <strong>butane</strong> and MachineConfig as per the KB article at post install time to configure <strong>mirror-by-digest-only = false</strong> for my mirror registries that need it. From my <a href="https://github.com/eformat/acm-gitops-ocp">git repo</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">butane 99-master-mirror-by-digest-registries.bu -o 99-master-mirror-by-digest-registries.yaml
oc apply -f 99-master-mirror-by-digest-registries.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will reboot your nodes to apply the MCP, you may add or change the butane template(s) and yaml to suit the nodes you need to target e.g. masters or workers (or any other) node role. In my case it&#8217;s targeting a SNO cluster so master is fine.</p>
</div>
<div class="paragraph">
<p>All going well your marketplace pods should now pull images and run OK</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc get pods -n openshift-marketplace
NAME                                   READY   STATUS    RESTARTS   AGE
certified-operators-d2nd9              1/1     Running   0          16h
community-operators-k662l              1/1     Running   0          16h
marketplace-operator-84457bfc9-v22db   1/1     Running   5          16h
redhat-marketplace-kjrt9               1/1     Running   0          16h
redhat-operators-62z6x                 1/1     Running   0          16h</code></pre>
</div>
</div>
<div class="paragraph">
<p>A word of warning when using the Assited Installer / Agent Installer method. If you try to set <strong>mirror-by-digest-only = false</strong> registries in your <strong>AgentServiceConfig</strong> using the provided ConfigMap e.g. something like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: quay-mirror-config
  namespace: multicluster-engine
  labels:
    app: assisted-service
data:
  LOG_LEVEL: "debug"
  ca-bundle.crt: |
    -----BEGIN CERTIFICATE-----
    ! Put you CA for your mirror registry here !
    -----END CERTIFICATE-----

  registries.conf: |
    unqualified-search-registries = ["registry.redhat.io", "registry.access.redhat.com", "docker.io"]

    [[registry]]
      prefix = ""
      location = "registry.redhat.io/redhat"
      mirror-by-digest-only = false
      [[registry.mirror]]
        location = "quay.eformat.me:8443/registry-redhat-io/redhat"</code></pre>
</div>
</div>
<div class="paragraph">
<p>The registry mirror setting will get reset to <strong>mirror-by-digest-only = true</strong> by the installer.</p>
</div>
<div class="paragraph">
<p>Similarly, if you try and set MachineConfig in the <strong>ignitionConfigOverride</strong> in the <strong>InfraEnv</strong> e.g.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">apiVersion: agent-install.openshift.io/v1beta1
kind: InfraEnv
...
  # User for modify ignition during discovery
  ignitionConfigOverride: '{"ignition": {"version": "3.1.0"}, "storage": {"files": [{"path": "/etc/containers/registries.conf", "mode": 420, "overwrite": true, "user": { "name": "root"},"contents": {"source": "data:text/plain;base64,dW5xd..."}}]}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>it also gets overriden by the installer. I tried both these methods and failed üò≠üò≠</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary">Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>For now, the only way to configure <strong>mirror-by-digest-only = false</strong> is via MachineConfig <strong>post-install</strong>.</p>
</div>
<div class="paragraph">
<p>You can always <strong>try</strong> and only mirror images by digest, just remember that various operators and components may not be configured this work this way.</p>
</div>
<div class="paragraph">
<p>The future looks bright with the new API&#8217;s, as this has been a long-standing issue now.</p>
</div>
<div class="paragraph">
<p>üèÖGood luck installing out there !!</p>
</div>
</div>
</div></p>
                <p><a href="2023/04/disconnected-registries.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2023/02/acm-team-argocd.html"><h1>ACM &amp; ArgoCD for Teams</h1></a>
                <p>17 February 2023</p>

                <p>Tags :
                <a href="openshift.html">openshift</a>, <a href="argocd.html">argocd</a>, <a href="acm.html">acm</a>, <a href="gitops.html">gitops</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2023/02/acm-team-argocd.html" data-text="ACM &amp; ArgoCD for Teams" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2023/02/acm-team-argocd.html"></div>

                <p><div class="sect1">
<h2 id="_quickly_deploying_argocd_applicationsets_using_rhacms_global_clusterset">Quickly deploying ArgoCD ApplicationSets using RHACM&#8217;s Global ClusterSet</h2>
<div class="sectionbody">
<div id="lightbox"></div>
<div class="imageblock id="gpu-concurrency-mechanisms">
  <img src="/2023/02/sre-cluster-argo-team-namespaced.png" class="zoom">
</div>
<div class="paragraph">
<p>I have <a href="https://github.com/eformat/argocd-team-topologies">written about</a> how we can align our Tech to setup GitOps tooling so that it fits with our team structure.</p>
</div>
<div class="paragraph">
<p>How can we make these patterns real using tools like Advanced Cluster Manager (ACM) that help us deploy to a fleet of Clusters ? ACM supports <code>Policy</code> based deployments so we can track compliance of our clusters to the expected configuration management policy.</p>
</div>
<div class="paragraph">
<p>The source code is here - <a href="https://github.com/eformat/acm-gitops" class="bare">https://github.com/eformat/acm-gitops</a> - git clone it so you can follow along.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_global_clustersets">Global ClusterSet&#8217;s</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When a cluster is managed in ACM there are several resources created out of the box <a href="https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.6/html-single/multicluster_engine/index#managedclustersets_global">you can read about them here</a> in the documentation. This includes a namespace called <code>open-cluster-management-global-set</code>. We can quickly deploy <code>ApplicationSet&#8217;s</code> in this global-namespace that generates <code>Policy</code> to create our team based ArgoCD instances.</p>
</div>
<div class="paragraph">
<p>We can leverage the fact that <code>ApplicationSet&#8217;s</code> can be associated with a <code>Placement</code> - that way we can easily control where our <code>Policy</code> and <code>Team ArgoCD&#8217;s</code> are deployed across our fleet of OpenShift clusters by using simple label selectors for example.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_bootstrap_a_cluster_scoped_argocd_for_our_policies">Bootstrap a Cluster Scoped ArgoCD for our Policies</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We are going Bootstrap a cluster-scoped ArgoCD instance into the <code>open-cluster-management-global-set</code> namespace.</p>
</div>
<div class="paragraph">
<p>We will deploy our Team ArgoCD&#8217;s using ACM <code>Policy</code> that is generated using the <code>PolicyGenerator</code> tool <a href="https://github.com/stolostron/policy-generator-plugin/blob/main/docs/policygenerator-reference.yaml">which you can read about here from its' reference file</a>.</p>
</div>
<div class="paragraph">
<p>Make sure to label the cluster&#8217;s where you want to deploy to with <code>useglobal=true</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f bootstrap-acm-global-gitops/setup.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>This deploys the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Subscription</code> Resource - The GitOps operator <code>Subscription</code>, including disabling the default ArgoCD and setting cluster-scoped connections for our namespaces - see the <code>ARGOCD_CLUSTER_CONFIG_NAMESPACES</code> env.var that is part of the <code>Subscription</code> object. If your namespace is not added here, you will get namespace scoped connections for your ArgoCD, rather than all namespaces.</p>
</li>
<li>
<p><code>GitOpsCluster</code> Resource - This resource provides a Connection between ArgoCD-Server and the Placement (where to deploy exactly the Application).</p>
</li>
<li>
<p><code>Placement</code> Resource - We use a <code>Placement</code> resource for this global ArgoCD which deploys to a fleet of Clusters, where the Clusters needs to be labeled with <code>useglobal=true</code>.</p>
</li>
<li>
<p><code>ArgoCD</code> Resource - The CR for our global ArgoCD where we will deploy Policy. We configure ArgoCD to download the <code>PolicyGenerator</code> binary, and configure kustomize to run with the setting:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">kustomizeBuildOptions: --enable-alpha-plugins</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deploy_the_team_based_argocd_using_generated_policy">Deploy the Team Based ArgoCD using Generated Policy</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We are going to deploy ArgoCD for two teams now using the ACM <code>PolicyGenerator</code>.</p>
</div>
<div class="paragraph">
<p>The <code>PolicyGenerator</code> runs using kustomize. We specify the <code>generator-input/</code> folder - that holds our YAML manifests for each ArgoCD - in this case one for <code>fteam</code>, one for <code>zteam</code>.</p>
</div>
<div class="paragraph">
<p>You can run the <code>PolicyGenerator</code> from the CLI to test it out before deploying - download it using the <a href="https://github.com/stolostron/policy-generator-plugin/blob/main/README.md)">instructions here</a> e.g.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">kustomize build --enable-alpha-plugins team-gitops-policy/</code></pre>
</div>
</div>
<div class="paragraph">
<p>We specify the placement rule <code>placement-team-argo</code> - where the Clusters needs to be labeled with <code>teamargo=true</code>.</p>
</div>
<div class="paragraph">
<p>We add some default compliance and control labels for grouping purposes in ACM Governance.</p>
</div>
<div class="paragraph">
<p>We also set the <code>pruneObjectBehavior: "DeleteAll</code> so that if we delete the <code>ApplicationSet</code> the generated <code>Policy</code> s deleted and all objects are removed. For this to work, we must also set the <code>remediationAction</code> to <code>enforce</code> for our Policies.</p>
</div>
<div class="paragraph">
<p>One last configuration is to set the ArgoCD <code>IgnoreExtraneous</code> compare option - as Policy is generated we do not want ArgoCD to be out of sync for these objects.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">apiVersion: policy.open-cluster-management.io/v1
kind: PolicyGenerator
metadata:
  name: argocd-teams
placementBindingDefaults:
  name: argocd-teams
policyDefaults:
  placement:
    placementName: placement-team-argo
  categories:
    - CM Configuration Management
  complianceType: "musthave"
  controls:
    - CM-2 Baseline Configuration
  consolidateManifests: false
  disabled: false
  namespace: open-cluster-management-global-set
  pruneObjectBehavior: "DeleteAll"
  remediationAction: enforce
  severity: medium
  standards:
    - generic
  policyAnnotations: {"argocd.argoproj.io/compare-options": "IgnoreExtraneous"}
policies:
  - name: team-gitops
    manifests:
      - path: generator-input/</code></pre>
</div>
</div>
<div class="paragraph">
<p>Make sure to label the cluster&#8217;s where you want to deploy to with <code>teamargo=true</code>.</p>
</div>
<div class="paragraph">
<p>To create our Team ArgoCD&#8217;s run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f applicationsets/team-argo-appset.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>To delete them, remove the <code>AppSet</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc delete appset team-argo</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_summary">Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You can now take this pattern and deploy it across multiple clusters that are managed by ACM. You can easily scale out the number of Team Based ArgoCD and have fine grained control over their individual configuration including third party plugins like Vault. ACM offers a single plane of glass to check if your clusters are compliant to the generated policies, and if not - take remedial action.</p>
</div>
<div class="paragraph">
<p>You can see the code in action in this video.</p>
</div>
<div class="videoblock">
<div class="content">
<iframe width="800" height="600" src="https://www.youtube.com/embed/eGxPMkADAbc?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
<div class="paragraph">
<p>üèÖEnjoy !!</p>
</div>
</div>
</div></p>
                <p><a href="2023/02/acm-team-argocd.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2023/02/sno-metallb-bpg.html"><h1>SNO, MetalLB, BGP</h1></a>
                <p>02 February 2023</p>

                <p>Tags :
                <a href="openshift.html">openshift</a>, <a href="metallb.html">metallb</a>, <a href="bgp.html">bgp</a>, <a href="frr.html">frr</a>, <a href="bird.html">bird</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2023/02/sno-metallb-bpg.html" data-text="SNO, MetalLB, BGP" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2023/02/sno-metallb-bpg.html"></div>

                <p><div class="sect1">
<h2 id="_using_sno_and_metallb_in_bgp_mode">Using SNO and MetalLB in BGP Mode</h2>
<div class="sectionbody">
<div class="paragraph">
<p>So yeah, i was reading <a href="https://cloud.redhat.com/blog/metallb-in-bgp-mode">this awesome blog post on 'How to Use MetalLB in BGP Mode'</a> and thought i need to give this a try with SNO at home.</p>
</div>
<div class="paragraph">
<p>I won&#8217;t repeat all the details linked in that post, please go read it before trying what comes next as i reference it. Suffice to say the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>SNO</strong> - Single Node OpenShift</p>
</li>
<li>
<p><strong>MetalLB</strong> - creates <code>LoadBalancer</code> types of Kubernetes services on top of a bare-metal (like) OpenShift/Kubernetes. I&#8217;m going to do it in a kvm/libvirt lab.</p>
</li>
<li>
<p><strong>BGP</strong> - Border Gateway Protocol - runs and scales the internet - (ftw! seriously, go read about bpg hijacking) - with MetalLB we can use BGP mode to statelessly load balance client traffic towards the applications running on bare metal-like OpenShift clusters.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The idea is that you can have both normal Routing/HAProxy service <code>ClusterIP&#8217;s</code> on the SDN as well as <code>LoadBalancer&#8217;s</code> being served by BGP/MetalLB in your SNO Cluster. OpenShift SDN (OVNKubernetes as well as OPenShiftSDN) both support MetalLB out of the box.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_lab_setup">The Lab Setup</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_networking_services">Networking Services</h3>
<div class="paragraph">
<p>There are some complexities in my home lab, mainly caused by the constraint of having teenagers who feel good bandwidth is a basic human <em>right</em> and not a <em>luxury</em>.</p>
</div>
<div class="paragraph">
<p>So i need to keep the connections to their myriad of devices running smoothly as well as serving my own geek needs. To make this happen and keep things relatively simple, i have a pretty standard setup and use my Mesh network. I am not trying any telco grade stuff (e.g. SRIOV) - so have no main Cisco/vendor switching involved.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="gpu-concurrency-mechanisms">
  <img src="/2023/02/lab-network.png" class="zoom">
</div>
<div class="paragraph">
<p><strong>Router</strong> - Plain old broadband router with firewall and port-forwarding facilities.</p>
</div>
<div class="paragraph">
<p><strong>Mesh Network</strong> - Connectivity via Wifi Mesh, 1G Ethernet around the house, comes with another firewall and port-forwarding facilities.</p>
</div>
<div class="paragraph">
<p><strong>VMHost</strong> - Fedora Core box running libvirt/kvm. Has thin-lvm, nvme based storage. Hosts DNS, HTTPD, HAProxy services. Multiple network connections including eht0 which is bridged directly to the lab hosts via br0. When you add the virsh network, also make sure to <a href="https://wiki.libvirt.org/page/Net.bridge.bridge-nf-call_and_sysctl.conf">change the defaults for bridge mode to</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">cat /etc/sysctl.d/99-netfilter-bridge.conf
net.bridge.bridge-nf-call-ip6tables = 0
net.bridge.bridge-nf-call-iptables = 0
net.bridge.bridge-nf-call-arptables = 0

cat /etc/modules-load.d/br_netfilter.conf
br_netfilter

sudo sysctl -p /etc/sysctl.d/99-netfilter-bridge.conf</code></pre>
</div>
</div>
<div class="paragraph">
<p>And the bridge looks like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">cat &lt;&lt;EOF &gt; /etc/libvirt/qemu/networks/sno.xml
&lt;network&gt;
  &lt;name&gt;sno&lt;/name&gt;
  &lt;uuid&gt;fc43091f-de22-4bf5-974b-98711b9f3d9e&lt;/uuid&gt;
  &lt;forward mode="bridge"/&gt;
  &lt;bridge name='br0'/&gt;
&lt;/network&gt;
EOF

virsh net-define /etc/libvirt/qemu/networks/sno.xml
virsh net-start sno
virsh net-autostart sno</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you have a firewall on this host (firewalld, iptables) make sure to allow these ports and traffic to flow: 179/TCP (BGP), 3784/UDP and 3785/UDP (BFD).</p>
</div>
<div class="paragraph">
<p><strong>SNO</strong> - Single Node OpenShift 4.12 libvirt/kvm installed <a href="https://github.com/eformat/ocp4-sno-inplace">using libvirt Bootstrap In-Place methodology</a> from a single iso. A snippet from my install-config file showing the networking setup.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">cat &lt;&lt; EOF &gt; install-config.yaml
...
networking:
  networkType: OVNKubernetes
  machineNetwork:
  - cidr: 192.168.86.0/24</code></pre>
</div>
</div>
<div class="paragraph">
<p>When doing boostrap in-place, normally you rely on DHCP assignment for hostname, ip, dns, gateway. However, due to my DHCP being mesh controlled i modified the installer ISO to setup the networking manually. Set up so we copy the network form the boostrap image:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">cat &lt;&lt; EOF &gt; install-config.yaml
...
bootstrapInPlace:
  installationDisk: "--copy-network /dev/vda"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Setup the ip address, gateway, network, hostname, device, dns as <a href="https://docs.openshift.com/container-platform/4.12/installing/installing_bare_metal/installing-restricted-networks-bare-metal.html#installation-user-infra-machines-advanced_installing-bare-metal">per the OpenShift docs.</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">arg1="rd.neednet=1"
arg2="ip=192.168.86.32::192.168.86.1:255.255.255.0:sno:enp1s0:none nameserver=192.168.86.27"
coreos-installer iso customize rhcos-live.x86_64.iso --live-karg-append="${arg1}" --live-karg-append="${arg2}" -f</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>DNS</strong> - I run bind/named on my VMHost to control OpenShift api.* and apps.* cluster domain. The SOA is in the cloud, so I can route from anywhere to the FQDN OK. In the lab, the internal DNS server just gives you the lab IP address. Externally you are forwarded to the Router which port-forwards via the firewall&#8217;s and Mesh to the correct SNO instance. I don&#8217;t show it, but I run HAProxy on the VMHost - that way I can serve external traffic to multiple OpenShift clusters in the lab simultaneously. My DNS zone looks like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">ns1       IN     A       192.168.86.27
api       IN     A       192.168.86.32
api-int   IN     A       192.168.86.32
*.apps    IN     A       192.168.86.32</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>DHCP</strong> - One of the drawback&#8217;s of my mesh tech is that it does not allow you to override DNS on a per host / DHCP assigned basis. This is required to setup OpenShift (need control over DNS etc). I could have installed another DHCP server on linux to do this job, but I just figured "no need", I will stick with the mesh as DHCP provider (see SNO section above for manual networking configuration).</p>
</div>
<div class="paragraph">
<p><strong>BGP</strong> - Once installed, the bpg network looks like this.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="gpu-concurrency-mechanisms">
  <img src="/2023/02/bgp-lab-network.png" class="zoom">
</div>
<div class="paragraph">
<p>When creating <code>LoadBalancer</code> services in SNO, MetalLB with the help of FRR binds an <code>External IP</code> to the service. Since we only have one SNO node, <code>BFD</code> is not in use like the article (multiple worker nodes as <code>BGPPeer&#8217;s</code>). That&#8217;s OK though we are just trying it out here!</p>
</div>
<div class="paragraph">
<p>A nice addition for demoing, is being able to configure a <a href="https://bird.network.cz">Bird</a> daemon on my Fedora Core laptop so that any BGP announcements are automatically added to its routing setup.</p>
</div>
<div class="paragraph">
<p><strong>FRR</strong> - RHEL8 VM running <a href="https://frrouting.org">FRRouting (FRR)</a> as a pod - this is an open source Internet routing protocol suite for Linux and Unix platforms. The configuration i used is from the linked blog post at the top. From the blog use the same <code>vtysh.conf</code> and <code>daemons</code> files. My <code>frr.conf</code> files was as folows - i added an additional entry for my Bird Client BGPPeer at <em>192.168.86.109</em></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">cat &lt;&lt;'EOF' &gt; /root/frr/frr.conf
frr version master_git
frr defaults traditional
hostname frr-upstream
!
debug bgp updates
debug bgp neighbor
debug zebra nht
debug bgp nht
debug bfd peer
log file /tmp/frr.log debugging
log timestamp precision 3
!
interface eth0
 ip address 192.168.86.23/24
!
router bgp 64521
 bgp router-id 192.168.86.23
 timers bgp 3 15
 no bgp ebgp-requires-policy
 no bgp default ipv4-unicast
 no bgp network import-check
 neighbor metallb peer-group
 neighbor metallb remote-as 64520
 neighbor 192.168.86.32 peer-group metallb
 neighbor 192.168.86.32 bfd
 neighbor 192.168.86.109 remote-as external
!
 address-family ipv4 unicast
  neighbor 192.168.86.32 next-hop-self
  neighbor 192.168.86.32 activate
  neighbor 192.168.86.109 next-hop-self
  neighbor 192.168.86.109 activate
 exit-address-family
!
line vty
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p>Running FRR with podman is pretty straight forward:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">podman run -d --rm  -v /root/frr:/etc/frr:Z --net=host --name frr-upstream --privileged quay.io/frrouting/frr:master</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some useful commands i found to show you the BGP/FRR details:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">podman exec -it frr-upstream vtysh -c "show ip route"
podman exec -it frr-upstream ip r
podman exec -it frr-upstream vtysh -c "show ip bgp sum"
podman exec -it frr-upstream vtysh -c "show ip bgp"
podman exec -it frr-upstream vtysh -c "show bfd peers"
podman exec -it frr-upstream vtysh -c "show bgp summary"
podman exec -it frr-upstream vtysh -c "show ip bgp neighbor"</code></pre>
</div>
</div>
<div class="paragraph">
<p>As in the blog post, when looking at your "show ip bgp neighbor" you should see <strong>BGP state = Established</strong> for the <code>BGPPeers</code> once everything is connected up.</p>
</div>
<div class="paragraph">
<p><strong>MetalLB</strong> - Installed on SNO as per the blog post. Check there for a detailed explanation. The commands I used were as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: v1
kind: Namespace
metadata:
name: metallb-system
spec: {}
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
name: metallb-operator
namespace: metallb-system
spec: {}
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
name: metallb-operator-sub
namespace: metallb-system
spec:
name: metallb-operator
channel: "stable"
source: redhat-operators
sourceNamespace: openshift-marketplace
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc get installplan -n metallb-system
oc get csv -n metallb-system -o custom-columns='NAME:.metadata.name, VERSION:.spec.version, PHASE:.status.phase'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: metallb.io/v1beta1
kind: MetalLB
metadata:
name: metallb
namespace: metallb-system
spec:
nodeSelector:
node-role.kubernetes.io/worker: ""
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
name: address-pool-bgp
namespace: metallb-system
spec:
addresses:
- 192.168.155.150/32
- 192.168.155.151/32
- 192.168.155.152/32
- 192.168.155.153/32
- 192.168.155.154/32
- 192.168.155.155/32
autoAssign: true
protocol: bgp
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: metallb.io/v1beta1
kind: BFDProfile
metadata:
name: test-bfd-prof
namespace: metallb-system
spec:
detectMultiplier: 37
echoMode: true
minimumTtl: 10
passiveMode: true
receiveInterval: 35
transmitInterval: 35
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: metallb.io/v1beta1
kind: BGPPeer
metadata:
name: peer-test
namespace: metallb-system
spec:
bfdProfile: test-bfd-prof
myASN: 64520
peerASN: 64521
peerAddress: 192.168.86.23
EOF</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
apiVersion: metallb.io/v1beta1
kind: BGPAdvertisement
metadata:
name: announce-test
namespace: metallb-system
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Client</strong> - Fedora Core laptop i&#8217;m writing this blog post on ;) I installed Bird and configured it to <code>import</code> all bgp addresses from the <code>FRR</code> neighbour as follows.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">dnf install -y bird

cat &lt;&lt;'EOF' &gt; /etc/bird.conf
log syslog all;
protocol kernel {
        ipv4 {
              import none;
              export all;
        };
        ipv6 {
              import none;
              export all;
        };
}
protocol direct {
        disabled;               # Disable by default
        ipv4;                   # Connect to default IPv4 table
        ipv6;                   # ... and to default IPv6 table
}
protocol static {
        ipv4;
}
protocol device {
        scan time 10;
}
protocol bgp {
        description "OpenShift FFR+MetalLB Routes";
        local as 64523;
        neighbor 192.168.86.23 as 64521;
        source address 192.168.86.109;
        ipv4 {
            import all;
            export none;
        };
}
EOF

systemctl start bird
journalctl -u bird.service</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_workload_demo">Workload Demo</h2>
<div class="sectionbody">
<div class="paragraph">
<p>OK, time to try this out with a real application on OpenShift. I am going to use a very simple hello world container.</p>
</div>
<div class="paragraph">
<p>Login to the SNO instance and create a namespace and a deployment.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc new-project welcome-metallb
oc create deployment welcome --image=quay.io/eformat/welcome:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now create a <code>LoadBalancer</code> type service, MetalLB will do its thing.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f- &lt;&lt;'EOF'
---
apiVersion: v1
kind: Service
metadata:
  name: welcome
spec:
  selector:
    app: welcome
  ports:
    - port: 80
      protocol: TCP
      targetPort: 8080
  type: LoadBalancer
EOF</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can see an <code>ExternalIP</code> was assigned along with a <code>NodePort</code> by MetalLB.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc get svc

NAME      TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)        AGE
welcome   LoadBalancer   172.30.154.119   192.168.155.150   80:30396/TCP   7s</code></pre>
</div>
</div>
<div class="paragraph">
<p>If we describe the service, we can see that the address was also <strong>announced</strong> over BGP.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc describe svc welcome

Name:                     welcome
Namespace:                welcome-metallb
Labels:                   &lt;none&gt;
Annotations:              &lt;none&gt;
Selector:                 app=welcome
Type:                     LoadBalancer
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       172.30.154.119
IPs:                      172.30.154.119
LoadBalancer Ingress:     192.168.155.150
Port:                     &lt;unset&gt;  80/TCP
TargetPort:               8080/TCP
NodePort:                 &lt;unset&gt;  30396/TCP
Endpoints:                10.128.0.163:8080
Session Affinity:         None
External Traffic Policy:  Cluster
Events:
  Type    Reason        Age   From                Message
  ----    ------        ----  ----                -------
  Normal  IPAllocated   57s   metallb-controller  Assigned IP ["192.168.155.150"]
  Normal  nodeAssigned  57s   metallb-speaker     announcing from node "sno" with protocol "bgp"</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can check on our <strong>FRR</strong> Host the BGP route was seen:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">[root@rhel8 ~]# podman exec -it frr-upstream   vtysh -c "show ip route"
Codes: K - kernel route, C - connected, S - static, R - RIP,
       O - OSPF, I - IS-IS, B - BGP, E - EIGRP, N - NHRP,
       T - Table, v - VNC, V - VNC-Direct, A - Babel, F - PBR,
       f - OpenFabric,
       &gt; - selected route, * - FIB route, q - queued, r - rejected, b - backup
       t - trapped, o - offload failure

K&gt;* 0.0.0.0/0 [0/100] via 192.168.86.1, eth0, src 192.168.86.23, 19:16:24
C&gt;* 192.168.86.0/24 is directly connected, eth0, 19:16:24
B&gt;* 192.168.155.150/32 [20/0] via 192.168.86.32, eth0, weight 1, 00:02:12</code></pre>
</div>
</div>
<div class="paragraph">
<p>And from our <strong>Client</strong> that Bird also added the route correctly from the announcement:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">route -n

Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.86.1    0.0.0.0         UG    600    0        0 wlp2s0
192.168.86.0    0.0.0.0         255.255.255.0   U     600    0        0 wlp2s0
192.168.155.150 192.168.86.23   255.255.255.255 UGH   32     0        0 wlp2s0</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can try the app endpoint from our <strong>Client</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ curl 192.168.155.150:80
Hello World ! Welcome to OpenShift from welcome-5575fd7854-7hlxj:10.128.0.163</code></pre>
</div>
</div>
<div class="paragraph">
<p>üçæüçæ Yay ! success. üçæüçæ</p>
</div>
<div class="paragraph">
<p>If we deploy the application <em>normally</em> using a Route</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc new-project welcome-router
oc new-app quay.io/eformat/welcome:latest
oc expose svc welcome</code></pre>
</div>
</div>
<div class="paragraph">
<p>and a <code>ClusterIP</code> type <code>Service</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc get svc welcome
NAME      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
welcome   ClusterIP   172.30.121.184   &lt;none&gt;        8080/TCP   62s</code></pre>
</div>
</div>
<div class="paragraph">
<p>We see that that MetalLB and normal HAProxy based Routing can happily co-exist in the same cluster.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ curl welcome-welcome-router.apps.foo.eformat.me
Hello World ! Welcome to OpenShift from welcome-8dcc64fcd-2ktv4:10.128.0.167</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you delete the <code>welcome-metallb</code> project or <code>LoadBalancer</code> service, you will see the BGP announcement to remove the routing OK.</p>
</div>
<div class="paragraph">
<p>üèÖThat&#8217;s it !! Go forth and BGP !</p>
</div>
</div>
</div></p>
                <p><a href="2023/02/sno-metallb-bpg.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2022/12/mastodon-openshift.html"><h1>Running Mastodon on OpenShift</h1></a>
                <p>31 December 2022</p>

                <p>Tags :
                <a href="openshift.html">openshift</a>, <a href="social.html">social</a>, <a href="fediverse.html">fediverse</a>, <a href="mastodon.html">mastodon</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2022/12/mastodon-openshift.html" data-text="Running Mastodon on OpenShift" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2022/12/mastodon-openshift.html"></div>

                <p><div class="sect1">
<h2 id="_join_the_fediverse_with_openshift">Join the Fediverse with OpenShift</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Who knew that <strong>fediverse</strong> was a portmanteau of "federation" and "universe" ? an ensemble of interconnected servers that are used for microblogging. If you are itching to try out your own Mastodon instance on OpenShift
i have just the <a href="https://github.com/eformat/openshift-mastodon">helm template</a> for you.</p>
</div>
<div class="paragraph">
<p>It should be as simple as logging into OpenShift and running helm, where <em>CLUSTER_DOMAIN</em> is your cluster apps domain name.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">helm upgrade --install my-fediverse . \
  --create-namespace --namespace mastodon \
  --set mastodon.local_domain=mastodon.&lt;CLUSTER DOMAIN&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will get you a basic server installed, using the lastest Mastodon image. You should change the <em>values.yaml</em> to adjust the default passwords and secrets prior to deploying anything other than a play-around instance - see the README.md for how to use rake to generate new secrets. Once deployed, you should see these pods running in your <strong>mastodon</strong> namespace.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="mastodon-pods">
  <img src="/2022/12/mastodon-pods.png" class="zoom">
</div>
<div class="sect2">
<h3 id="_a_note_on_s3">A note on S3</h3>
<div class="paragraph">
<p>Mastodon can store its microblogging images in S3. The helm chart uses a <a href="https://min.io">minio</a> instance running in OpenShift. In the default configuration, we want the s3 links to be publicly available via anonymous read-only access with the link, but not listable. For now we use the aws cli client to upload this policy manually post-install.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc -n mastodon port-forward svc/my-fediverse-minio 9000:9000
cat &lt;&lt; 'EOF' &gt; /tmp/mastodon-policy.json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": [
        "s3:GetObject"
      ],
      "Effect": "Allow",
      "Principal": {
        "AWS": [
          "*"
        ]
      },
      "Resource": [
        "arn:aws:s3:::mastodon/*"
      ],
      "Sid": ""
    }
  ]
}
EOF

export AWS_PROFILE=minio
aws --endpoint-url http://localhost:9000 s3api put-bucket-policy --bucket mastodon --policy file:///tmp/mastodon-policy.json</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_logging_in_adding_users">Logging In, Adding users</h3>
<div class="paragraph">
<p>By default users can self register to your mastodon instance. The user on boarding workflow uses email, so you can deploy using SMTP services. For example a popular service like <a href="https://www.mailgun.com">mailgun</a> with your credentials would look something like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">helm upgrade --install my-fediverse . \
  --set mastodon.smtp_server=smtp.mailgun.org \
  --set mastodon.smtp_login=postmaster@example.com \
  --set mastodon.smtp_password=123456 \
  --set mastodon.smtp_from_address=mastodon@example.com. \
  --create-namespace --namespace mastodon</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you do not want to set up SMTP just yet, we can also use a manual method. Browse to your mastodon front page and select <strong>Create Account</strong>.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="mastodon-front-page">
  <img src="/2022/12/mastodon-front-page.png" class="zoom">
</div>
<div class="paragraph">
<p>This will let you sign up. We can rsh into the mastodon pod to manually approve the user. I signed up as <strong>eformat</strong> and also gave myself the <em>Admin</em> role.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc rsh $(oc get pods -l app.kubernetes.io/name=mastodon-streaming-mastodon -o name)

RAILS_ENV=production bin/tootctl accounts modify eformat --confirm
RAILS_ENV=production bin/tootctl accounts modify eformat --role Admin</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should see <strong>OK</strong> printed out when running these commands. Now log back in to mastodon and you should be able to right-click <strong>Preferences</strong> to administer the server.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="mastodon-admin">
  <img src="/2022/12/mastodon-admin.png" class="zoom">
</div>
<div class="paragraph">
<p>I updated the server thumbnail which is stored in your minio s3.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="mastodon-server-thumb">
  <img src="/2022/12/mastodon-server-thumb.png" class="zoom">
</div>
<div class="paragraph">
<p>üèÖThat&#8217;s it !! you can find all of the <a href="https://docs.joinmastodon.org/admin/config">docs and configuration guides</a> online for mastodon.</p>
</div>
</div>
</div>
</div></p>
                <p><a href="2022/12/mastodon-openshift.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2022/12/nvidia-gpu-sharing.html"><h1>Stable Diffusion on OpenShift with GPU Sharing</h1></a>
                <p>13 December 2022</p>

                <p>Tags :
                <a href="openshift.html">openshift</a>, <a href="gpu.html">gpu</a>, <a href="aiml.html">aiml</a>, <a href="stable diffusion.html">stable diffusion</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2022/12/nvidia-gpu-sharing.html" data-text="Stable Diffusion on OpenShift with GPU Sharing" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2022/12/nvidia-gpu-sharing.html"></div>

                <p><div class="sect1">
<h2 id="_stable_diffusion_on_openshift_with_gpu_sharing">Stable Diffusion on OpenShift with GPU Sharing</h2>
<div class="sectionbody">
<div class="paragraph">
<p>So the intuitive follow on from the last blog post <a href="https://blog.eformat.me/2022/11/stable-diffusion.html">Stable Diffusion for Fedora Core</a> is of course to see if we can get the app running on OpenShift in a lab environment!</p>
</div>
<div class="paragraph">
<p>There are a couple of challenges. In my case, i actually wanted to demo the app in a lab that contains some older <a href="https://www.nvidia.com/en-au/data-center/tesla-t4/">Nvidia-Tesla-T4 GPU&#8217;s</a>, a bare metal SNO instance along with a bunch of other GPU enabled apps. This raises some interesting questions, in particular how do we configure and deploy applications so they can share the GPU&#8217;s in this environment?</p>
</div>
<div class="paragraph">
<p>One of the best article i found <a href="https://developer.nvidia.com/blog/improving-gpu-utilization-in-kubernetes">describing GPU Sharing</a> and the various mechanisms involved, highlights the different options available.</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="gpu-concurrency-mechanisms">
  <img src="/2022/12/gpu-concurrency-mechanisms.png" class="zoom">
</div>
<div class="paragraph">
<p>We are interested primarily in the system software and hardware part of this picture (CUDA and MPS-CUDA are more at the application level). Although, Stable Diffusion does require working CUDA for python torch as well.</p>
</div>
<div class="paragraph">
<p><code>MIG</code> (which stands for multi instance GPU) is the newest technology and only supported on a small number of cards (not the T4') like vGPU (A100 and A30). There are some great <a href="https://www.openshift.com/blog/multi-instance-gpu-support-with-the-gpu-operator-v1.7.0">OpenShift blogs</a> describing MIG usage. vGPU is a technology that is <strong>only</strong> available if OpenShift is running in a VM/hypervisor. vGPUs are created/configured at the hypervisor level independently of OpenShift.</p>
</div>
<div class="paragraph">
<p>So, that leaves us with <strong>Time-slicing</strong>. The <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/time-slicing-gpus-in-openshift.html#configuring-gpus-with-time-slicing">best place to read about it</a> is on the Nvidia site. Unlike MIG, there is no memory or fault-isolation between replicas, but for some workloads this is better than not being able to share the GPU at all. <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/gpu-sharing.html">There is a lot of documentation</a> to read, so i&#8217;m going to summarize the steps to get OpenShift Bare Metal SNO working using time-slicing.</p>
</div>
<div class="sect2">
<h3 id="_installing_the_node_feature_discovery_nfd_operator">Installing the Node Feature Discovery (NFD) Operator</h3>
<div class="paragraph">
<p>The first step after installing OpenShift SNO bare-metal, was to configure the NFD operator as cluster-admin. The default configuration for the operator is fine. All going well, your GPU&#8217;s should now be visible to OpenShift, and you can check by doing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc debug node/&lt;node name&gt;
$ chroot /host
$ lspci | grep -i nvidia
17:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
65:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can see our two physical GPU&#8217;s OK. Another check is the node labels and description:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc describe node | egrep 'Roles|pci' | grep -v master
   feature.node.kubernetes.io/pci-10de.present=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you see the <strong>pci-10de</strong> device, that is the code for Nvidia GPU&#8217;s, all good so far.</p>
</div>
</div>
<div class="sect2">
<h3 id="_installing_the_nvidia_gpu_operator">Installing the NVIDIA GPU Operator</h3>
<div class="paragraph">
<p>Next step is to <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/install-gpu-ocp.html">install the Nvidia GPU Operator</a>. By default you should <strong>not</strong> need to install any license as <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/steps-overview.html#entitlement-free-supported-versions">OpenShift 4.9.9+ is entitlement free</a>. There are several pods that install with this operator. If you install the default <code>Cluster Policy</code> the nvidia driver is downloaded and compiled for your OpenShift and inserted as dynamic <strong>kmods</strong>. This may take a little bit of time to complete.</p>
</div>
<div id="nvidia-driver" class="paragraph">
<p><span class="image"><img src="/2022/12/nvidia-driver-pod.png" alt="Nvidia Dameon Set" width="640" height="480"></span></p>
</div>
<div class="paragraph">
<p>In our case, we only have one node (SNO) so the dameon set compiles and installs the driver on our node. If you follow the documentation above you should be able to verify the drivers are loaded.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc debug node/&lt;node name&gt;
$ chroot /host
$ lsmod | grep nvidia
nvidia_modeset       1142784  0
nvidia_uvm           1310720  2
nvidia              40796160  363 nvidia_uvm,nvidia_modeset
drm                   589824  4 drm_kms_helper,nvidia,mgag200</code></pre>
</div>
</div>
<div class="paragraph">
<p>Its worth noting that if you were using vGPU, you would <strong>also</strong> get the <em>nvidia_vgpu_vfio</em> module, but because we are bare metal, the driver dameon set recognizes passthrough mode and does not compile it.</p>
</div>
<div class="paragraph">
<p>The second part of the puzzle is you need to now configure the GPU for time-slicing. To do this we need create a ConfigMap that specifies how many slices we want, for example <em>8</em> in our case.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: time-slicing-config
  namespace: nvidia-gpu-operator
data:
  tesla-t4: |-
    version: v1
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 8</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, we add this ConfigMap name into the nvidia.com ClusterPolicy.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">                  devicePlugin:
                    config:
                      default: "tesla-t4"
                      name: "time-slicing-config"
                    enabled: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>By enabling the <em>devicePlugin</em> you should see the device plugin DaemonSet spin up.</p>
</div>
<div id="nvidia-deive-plugin" class="paragraph">
<p><span class="image"><img src="/2022/12/nvidia-device-plugin.png" alt="Nvidia Device Plugin Dameon Set" width="640" height="480"></span></p>
</div>
<div class="paragraph">
<p>We are nearly there ! If we now look at the OpenShift node description, we should see how many GPU&#8217;s OpenShift now thinks it has.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ oc describe node| sed '/Capacity/,/System/!d;/System/d'

Capacity:
  ...
  nvidia.com/gpu:                 16
Allocatable:
  ...
  nvidia.com/gpu:                 16</code></pre>
</div>
</div>
<div class="paragraph">
<p>So great ! that is <strong>8x2=16</strong> time-sliced GPU&#8217;s available.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deploy_stable_diffusion">Deploy Stable Diffusion</h3>
<div class="paragraph">
<p>I have created a simple <a href="https://github.com/eformat/stable-diffusion/tree/main/openshift">Kustomize folder</a> in the git repo and split out the two part needed to get the app running.</p>
</div>
<div class="paragraph">
<p>First create a data download job (this is 6 GB of downloads), which creates a PVC using he default Storage Class to download the required Stable Diffusion model data.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f create-data/app.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then run the deployment.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc apply -f create-app/app.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here&#8217;s an example of a run on the lab, showing the <code>nvidia-smi pmon</code> on the shell for the running python process and an output text to image.</p>
</div>
<div class="imageblock id="stable-diffusion-gpu-time-slice">
  <img src="/2022/12/stable-diffusion-gpu-time-slice.png" class="zoom">
</div>
<div class="paragraph">
<p>In our Deployment we only requested one GPU, so we get one time-sliced gpu.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">        resources:
          limits:
            nvidia.com/gpu: 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can scale this up, or use the nvidia sample image to test out time-slicing and sharing e.g. Create a Deployment using this image.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="yaml">        replicas: 16
        image: nvidia/samples:dcgmproftester-2.0.10-cuda11.0-ubuntu18.04
        resources:
          limits:
            nvidia.com/gpu: "1"</code></pre>
</div>
</div>
<div class="paragraph">
<p>And hey presto ! we now see 15/16 app replicas spinning up and running on our 2 physical GPU&#8217;s. You can see them easily using <code>nvidia-smi pmon</code>. We don&#8217;t quite get to 16 as Stable Diffusion is still running on the GPU as well!</p>
</div>
<div class="imageblock id="stable-diffusion-gpu-time-slice">
  <img src="/2022/12/gpu-sharing-16.png" class="zoom">
</div>
</div>
</div>
</div></p>
                <p><a href="2022/12/nvidia-gpu-sharing.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2022/11/aws-sno-150.html"><h1>SNO in AWS for $150/mo</h1></a>
                <p>10 November 2022</p>

                <p>Tags :
                <a href="openshift.html">openshift</a>, <a href="aws.html">aws</a>, <a href="sno.html">sno</a>, <a href="cost.html">cost</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2022/11/aws-sno-150.html" data-text="SNO in AWS for $150/mo" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2022/11/aws-sno-150.html"></div>

                <p><div class="sect1">
<h2 id="_so_you_want_to_demo_openshift_like_a_boss">So you want to demo OpenShift like a boss &#8230;&#8203;</h2>
<div class="sectionbody">
<div id="money" class="paragraph">
<p><span class="image"><img src="/2022/11/100-unsplash.jpg" alt="Money" width="640" height="480"></span></p>
</div>
<div class="paragraph">
<p>What is the cheapest way to run OpenShift in the public cloud ?</p>
</div>
<div class="paragraph">
<p>Behold .. the awesomeness-ness of SNO (Single Node OpenShift) on persistent <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html">spot in AWS</a>. A Spot Instance is an instance that uses spare EC2 capacity that is available for a lot less than the On-Demand price. How much less ? well.. you can <a href="https://aws.amazon.com/ec2/spot/pricing">check it out here</a> but normally 70% less ec2 cost. Just get used to some interruptions üò∂‚Äçüå´Ô∏è.</p>
</div>
<div class="paragraph">
<p>For installing and demoing <em>anything</em> in OpenShift you will normally need a bare minimum of 8vCPU and 32 GB RAM for SNO which may get you close to under the $100 mark üò≤.</p>
</div>
<table class="tableblock frame-ends grid-all" style="width: 50%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-right valign-top"></th>
<th class="tableblock halign-center valign-top" colspan="2">Price</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock"><strong>m6a.2xlarge</strong></p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock"><code>$0.1658 per Hour</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>$120</em></p></td>
</tr>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock"><strong>GP3 volumes</strong></p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock"><code>approx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>$10</em></p></td>
</tr>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock"><strong>ELB+EIP</strong></p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock"><code>approx</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>$20</em></p></td>
</tr>
</tbody>
<tfoot>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock"><strong>Total:</strong></p></td>
<td class="tableblock halign-center valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>$150</em></p></td>
</tr>
</tfoot>
</table>
<div class="paragraph">
<p>But others could suit your need better:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>c5n.4xlarge - 16 vCPU, 42 GB RAM</p>
</li>
<li>
<p>m6a.2xlarge - 8 vCPU, 32 GB RAM</p>
</li>
<li>
<p>r6i.2xlarge - 8 vCPU, 64 GB RAM</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Prices will vary over time ! it is spot after all. The rate of instance <a href="https://aws.amazon.com/ec2/spot/instance-advisor">interruption</a> also varies by region and instance type, so I pick and choose based on latency to where I work from.</p>
</div>
<div class="paragraph">
<p>So, how do we get there ?</p>
</div>
<div class="paragraph">
<p>üí• <strong>UPDATE</strong> - Checkout the automation here - <a href="https://github.com/eformat/sno-for-100" class="bare">https://github.com/eformat/sno-for-100</a> üí•</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuring_and_installing_openshift">Configuring and Installing OpenShift</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You can <a href="https://docs.openshift.com/container-platform/4.11/installing/installing_sno/install-sno-installing-sno.html">check the docs</a> for configuring the install.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ openshift-install create install-config</code></pre>
</div>
</div>
<div class="paragraph">
<p>You want to install SNO, so your config should look similar to this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">apiVersion: v1
baseDomain: &lt;your base domain&gt;
compute:
- name: worker
  replicas: 0
controlPlane:
  name: master
  replicas: 1
  architecture: amd64
  hyperthreading: Enabled
  platform:
    aws:
      type: c5n.4xlarge
      rootVolume:
        size: 250
        type: gp3
metadata:
  name: sno
platform:
  aws:
    region: &lt;your region&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>You want a single master, choose how big you want your root volume and instance size and which region to install to. Personally I use <a href="https://github.com/openshift/hive/blob/master/docs/clusterpools.md">Hive and ClusterPools</a> from an SNO instance in my home lab to install all my public cloud clusters, that way I can easily control then via configuration and <a href="https://github.com/openshift/hive/blob/master/docs/hibernating-clusters.md">hibernate</a> them when I want ! You can also just install via the cli of course:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ openshift-install create cluster</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_adjusting_sno_to_remove_all_the_costly_networking_bits">Adjusting SNO to remove all the costly networking bits!</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When you install SNO, it installs a bunch of stuff you may not want in a demo/lab environment. With a single node, the load balancers and the private routing are usually not necessary at all. It&#8217;s always possible to put the private routing and subnets back if you need to add workers later or just reinstall.</p>
</div>
<div class="paragraph">
<p>I am going to include the aws cli commands as guidance, they need a bit more polish to make them fully scriptable, but we&#8217;re working on it ! This saves you approx~ $120/mo for the 3 NAT gateways, $40/mo for 2 API load balancers and $10/mo for 2 EIP&#8217;s. I will keep the router ELB.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Update Master Security Group: Allow 6443 (TCP)</p>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">region=&lt;your aws region&gt;
instance_id=&lt;your instance id&gt;
master_sg_name=&lt;your cluster&gt;-sno-master-sg

sg_master=$(aws ec2 describe-security-groups \
  --region=${region} \
  --query "SecurityGroups[].GroupId" \
  --filters "Name=vpc-id,Values=${vpc}" \
  --filters "Name=tag-value,Values=${master_sg_name}" | jq -r .[0])

aws ec2 authorize-security-group-ingress \
--region=${region} \
--group-id ${sg_master} \
--ip-permissions '[{"IpProtocol": "tcp", "FromPort": 6443, "ToPort":6443, "IpRanges": [{"CidrIp": "0.0.0.0/0"}]}]'</code></pre>
</div>
</div>
</li>
<li>
<p>Update Master Security Group: Allow 30000 to 32767 (TCP &amp; UDP) from 0.0.0.0/0 for NodePort services</p>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">aws ec2 authorize-security-group-ingress \
--region=${region} \
--group-id ${sg_master} \
--ip-permissions '[{"IpProtocol": "tcp", "FromPort": 30000, "ToPort":32767, "IpRanges": [{"CidrIp": "0.0.0.0/0"}]},{"IpProtocol": "udp", "FromPort": 30000, "ToPort":32767, "IpRanges": [{"CidrIp": "0.0.0.0/0"}]}]</code></pre>
</div>
</div>
</li>
<li>
<p>Add Security Groups that were attached to Routing ELB to master</p>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">aws ec2 authorize-security-group-ingress \
--region=${region} \
--group-id ${sg_master} \
--ip-permissions '[{"IpProtocol": "tcp", "FromPort": 443, "ToPort":443, "IpRanges": [{"CidrIp": "0.0.0.0/0"}]},{"IpProtocol": "tcp", "FromPort": 80, "ToPort":80, "IpRanges": [{"CidrIp": "0.0.0.0/0"}]},{"IpProtocol": "icmp", "FromPort": 8, "ToPort": -1,"IpRanges": [{"CidrIp": "0.0.0.0/0"}]}]'</code></pre>
</div>
</div>
</li>
<li>
<p>Attach a new public elastic IP address</p>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">eip=$(aws ec2 allocate-address --domain vpc --region=${region})

aws ec2 associate-address \
--region=${region} \
--allocation-id $(echo ${eip} | jq -r '.AllocationId') \
--instance-id ${instance_id}</code></pre>
</div>
</div>
</li>
<li>
<p>Update all subnets to route through IGW (using public route table)</p>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash"># update public route table and add private subnets to route through igw (using public route table), public subnets already route that way
aws ec2 describe-route-tables --filters "Name=vpc-id,Values=${vpc}" --region=${region} &gt; /tmp/baz

# inspect /tmp/baz to get the right id's, update them individually
aws ec2 replace-route-table-association \
--association-id rtbassoc-&lt;id&gt; \
--route-table-id rtb-&lt;id for igw&gt; \
--region=${region}</code></pre>
</div>
</div>
</li>
<li>
<p>Route53: Change API, APPS - A record to elastic IP address</p>
</li>
<li>
<p>Route53: Change internal API, APPS - A records to private IP address of instance</p>
<div class="paragraph">
<p>I&#8217;m just going to list the generic command here, rinse and repeat for each of the zone records (four times, [int, ext] - for [*.apps and api]):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">aws route53 list-hosted-zones

# get your hosted zone id's
hosted_zone=/hostedzone/&lt;zone id&gt;

# use the private ip address for the internal zone
cat &lt;&lt; EOF &gt; /tmp/route53_policy1
{
            "Changes": [
              {
                "Action": "UPSERT",
                "ResourceRecordSet": {
                  "Name": "api.&lt;your cluster domain&gt;",
                  "Type": "A",
                  "TTL": 300,
                  "ResourceRecords": [
                    {
                      "Value": "$(echo $eip | jq -r '.PublicIp')"
                    }
                  ]
                }
              }
            ]
          }
EOF

aws route53 change-resource-record-sets \
--region=${region} \
--hosted-zone-id $(echo ${hosted_zone} | sed 's/\/hostedzone\///g') \
--change-batch file:///tmp/route53_policy1</code></pre>
</div>
</div>
</li>
<li>
<p>Delete NAT gateways</p>
<div class="paragraph">
<p>This will delete all your nat gateways, adjust to suit</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">for i in `aws ec2 describe-nat-gateways --region=${region} --query="NatGateways[].NatGatewayId" --output text | tr '\n' ' '`; do aws ec2 delete-nat-gateway --nat-gateway-id ${i} --region=${region}; done</code></pre>
</div>
</div>
</li>
<li>
<p>Release public IP addresses (from NAT gateways)</p>
<div class="paragraph">
<p>There will be two public EIP&#8217;s you can now release:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">aws ec2 release-address \
--region=${region} \
--public-ip &lt;public ip address&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>Delete API load balancers (ext, int)</p>
<div class="paragraph">
<p>This will delete all your api load balancers, adjust to suit</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">for i in `aws elb describe-load-balancers --region=${region} --query="LoadBalancerDescriptions[].LoadBalancerName" --output text | tr '\n' ' '`; do aws elb delete-load-balancer --region=${region} --load-balancer-name ${i}; done</code></pre>
</div>
</div>
</li>
<li>
<p>Delete API load balancer target groups</p>
<div class="paragraph">
<p>FIXME - need to look these up</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">aws elbv2 delete-target-group \
--target-group-arn arn:aws:elasticloadbalancing:us-west-2:123456789012:targetgroup/my-targets/73e2d6bc24d8a067</code></pre>
</div>
</div>
</li>
<li>
<p>Use Host Network for ingress</p>
<div class="paragraph">
<p>FIXME - extra step</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc -n openshift-ingress-operator patch ingresscontrollers/default --type=merge --patch='{"spec":{"endpointPublishingStrategy":{"type":"HostNetwork","hostNetwork":{"httpPort": 80, "httpsPort": 443, "protocol": "TCP", "statsPort": 1936}}}}'
oc -n openshift-ingress delete services/router-default</code></pre>
</div>
</div>
</li>
<li>
<p>Restart SNO to ensure it still works !</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_convert_sno_to_spot">Convert SNO to SPOT</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This has the effect of creating a spot request which will be permanent and only stop the instance should the price or capacity not be met temporarily. We&#8217;re using <a href="https://pythonawesome.com/a-tool-to-convert-aws-ec2-instances-back-and-forth-between-on-demand">this script</a> to convert the SNO instance:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">$ ./ec2-spot-converter --stop-instance --review-conversion-result --instance-id &lt;your instance id&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will take a bit of time to run and gives good debugging info. You can delete any temporary ami&#8217;s and snapshots it creates.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_a_little_work_in_progress">A little work in progress &#8230;&#8203;</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The conversion script changes your instance id to a new one during the conversion. This stops the instance from registering in the router ELB properly. So we need to update the instance id in a few places in SNO - for now we need to do the following steps.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Update the machine api object</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc edit machine -n openshift-machine-api
# change your .spec.providerID to &lt;your new converted instance id&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>To make this survive a restart, we need to change the aws service provider id by hand on disk.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc debug node/&lt;your node name&gt;
chroot /host
cat /etc/systemd/system/kubelet.service.d/20-aws-providerid.conf

# the file will look like this with your region and instance
[Service]
Environment="KUBELET_PROVIDERID=aws:///&lt;region&gt;/&lt;your original instance id&gt;"

# edit this file using vi and change &lt;your original instance id&gt; -&gt; &lt;your new converted instance id&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Delete the node ! the kubelet will re-register itself on reboot # restart the service</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">oc delete node &lt;your node name&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Restart SNO</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can check the instance is correctly registered to the ELB.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="bash">aws elb describe-load-balancers \
--region=${region} \
--query="LoadBalancerDescriptions[].Instances" \
--output text</code></pre>
</div>
</div>
<div class="paragraph">
<p>I will update this blog if we get a better way to manage this instance id thing over time ü§ûü§ûü§û</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_profit">Profit !</h2>
<div class="sectionbody">
<div class="paragraph">
<p>üí∏üí∏üí∏ You should now be off to the races üèáüèª with your cheap-as SNO running on Spot.</p>
</div>
<div class="paragraph">
<p>The next steps - normally I would add a Lets Encrypt Cert, add users and configure the LVM Operator for thin-lvm based storage class. That i will leave those steps for another blog. Enjoy. ü§ë</p>
</div>
<div id="lightbox"></div>
<div class="imageblock id="sre-cluster-argo-team-namespaced">
  <img src="/2022/11/sno-aws.png" class="zoom">
  <div class="title">SNO for $150/mo in AWS on c5n.4xlarge</div>
</div>
</div>
</div></p>
                <p><a href="2022/11/aws-sno-150.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2022/11/devops-with-openshift-5yr.html"><h1>DevOps with OpenShift Introduction</h1></a>
                <p>03 November 2022</p>

                <p>Tags :
                <a href="devops.html">devops</a>, <a href="openshift.html">openshift</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2022/11/devops-with-openshift-5yr.html" data-text="DevOps with OpenShift Introduction" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2022/11/devops-with-openshift-5yr.html"></div>

                <p><div class="sect1 pagenumrestart">
<h2 id="Introduction-to-DevOps">5 Years!</h2>
<div class="sectionbody">
<div class="paragraph">
<p>It&#8217;s been five years since we wrote the inaugural DevOps with OpenShift book. I re-read the introduction recently, and thought <em>"It hasn&#8217;t aged that badly !"</em></p>
</div>
<div class="paragraph">
<p><a href="https://cloud.redhat.com/hubfs/pdfs/DevOps_with_OpenShift.pdf" class="bare">https://cloud.redhat.com/hubfs/pdfs/DevOps_with_OpenShift.pdf</a></p>
</div>
<div id="cover" class="imageblock">
<div class="content">
<img src="/2022/11/dowo_cover.png" alt="DevOps with OpenShift" width="640" height="480">
</div>
<div class="title">Figure 1. DevOps with OpenShift</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction_to_devops_with_openshift">Introduction to DevOps with OpenShift</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This book provides a practical guide for using OpenShift as an enablement technology for DevOps. OpenShift&#8217;s combination of container management platform with natively container-aware automation can bring those Developer and Operations constituencies together in ways not previously possible. This enables software work products to present themselves in a standardized form to your preferred continuous integration and delivery tool chains.</p>
</div>
<div class="paragraph">
<p>Container awareness makes it possible to leverage deployment strategies and quality of service characteristics honored by the container management platform and underlying orchestration engine. We can start thinking in terms of <em>containers-as-code</em> rather than <em>infrastructure-as-code</em>.</p>
</div>
<div class="paragraph">
<p>So to get started, let&#8217;s review some key DevOps concepts as interpreted with a container-centric viewpoint.</p>
</div>
<div class="sect2">
<h3 id="_devops">DevOps</h3>
<div class="paragraph">
<p>DevOps is concerned with aligning the constituents in the software delivery process to a common goal of value delivery&#x2014;and it&#8217;s not just Developers and Operators, but InfoSec and Quality Assurance functions and more. Recognize that wealth is created when the work product is valued by actors external to the production system. Value delivery outcomes are measured by metrics tied to production delivery velocity, quality, and waste. DevOps emphasizes behavioral- or cultural-related changes such as those which encourage teaming, inclusion, feedback, and experimentation. Technological interventions such as automation are central as they can reinforce such target behaviors. DevOps does not necessarily imply functional roles in software delivery such as development, quality assurance, or operations are merged or seconded. More important is that a professional respect and shared sensibility is formed across the delivery team.</p>
</div>
</div>
<div class="sect2">
<h3 id="_containers">Containers</h3>
<div class="paragraph">
<p>Containers are the runtime representation of a packaging format based on a lightweight, immutable image. Runtime dependencies are resolved within the image which facilitates portability. This makes possible the agreement on a standardized software work product. Management and runtime tooling that is container aware can then be applied consistently no matter what the underlying technology stack. Container-based workloads are suitable for multi-tenancy on a single compute instance and when implemented securely can realize significant operation efficiencies. An important corollary is that launching a new workload does not incur the cost of provisioning new compute infrastructure. This enables a true on-demand, self-service experience for users.</p>
</div>
</div>
<div class="sect2">
<h3 id="_container_orchestration">Container Orchestration</h3>
<div class="paragraph">
<p>Container orchestration involves the lifecycle management of container workloads, including functions such as to schedule, stop, start, and replicate across a cluster of machines. Compute resources for running workloads are abstracted, allowing the host infrastructure to be treated as a single logical deployment target. Kubernetes is an open source community project addressing container orchestration. It groups containers that make up an application into logical units for easy management and discovery, and features self-healing, service discovery, load balancing, and storage services among its rich feature set. Orchestration plays a critical role in our design goal of application-centricity as quality of service attributes and deployment patterns are executed by invoking Kubernetes API primitives.</p>
</div>
</div>
<div class="sect2">
<h3 id="_continuous_integration">Continuous Integration</h3>
<div class="paragraph">
<p>Continuous integration (CI) concerns the integration of code from potentially multiple authors into a shared source code management (SCM) repository. Such check-ins could occur many times a day, and automation steps in such a process could include gates or controls to expose any issues as early as possible. SCMs such as Git include¬†workflow support to commit to trunk, push, and merge code pull requests from multiple developers. With containers, a Git push event could be configured to then trigger an image build event via the webhooks mechanism.</p>
</div>
</div>
<div class="sect2">
<h3 id="_continuous_delivery">Continuous Delivery</h3>
<div class="paragraph">
<p>Once a CI strategy is in place, consideration can then move to achieving continuous delivery (CD). This involves automating the steps required to promote the work product from one environment to the next within the defined software development lifecycle (SDLC). Such steps could include automated testing, smoke, unit, functional, and static code analysis and static dependency checks for known security vulnerabilities. With containers, promotion in later stages of the SLC may merely involve the tagging of the (immutable) image to mark acceptance. Binary promotions are also possible such that only the image is pushed (to the target registry of the new environment), leaving source code in situ.</p>
</div>
</div>
<div class="sect2">
<h3 id="_continuous_deployment">Continuous Deployment</h3>
<div class="paragraph">
<p>By convention, we can denote the special case of automated continuous delivery to production as <em>continuous deployment</em> (CD). We make such a distinction because such deployments may be subject to additional governance processes and gates&#x2014;for example, deliberate human intervention to manage risk and complete sign-off procedures. We make such a distinction because such deployments may be subject to additional governance processes. As per <a href="#one_1">Continuous delivery versus deployment</a>, there may be scenarios for deliberate human intervention to manage risk and complete sign-off procedures.</p>
</div>
<div id="one_1" class="imageblock">
<div class="content">
<img src="/2022/11/dowo_0101.png" alt="Continuous Delivery versus Deployment">
</div>
<div class="title">Figure 2. Continuous delivery versus deployment</div>
</div>
</div>
<div class="sect2">
<h3 id="_pipelines">Pipelines</h3>
<div class="paragraph">
<p>Pipelines are a representation of the flow/automation in a CI/CD process. Typically a pipeline might call out discrete steps in the software delivery process and present them visually or via a high-level scripting language so the flow can be manipulated. The steps might include build, unit tests, acceptance tests, packaging, documentation, reporting, and deployment and verification phases. Well-designed pipelines help deliver better quality code faster by enabling participants in the software delivery process to more easily diagnose and respond to feedback. As illustrated in <a href="#one_2">Smaller releases, release often, faster feedback</a>, diagnosis and response turnaround can be accelerated by organizing releases into smaller and more frequent release bundles.</p>
</div>
<div id="one_2" class="imageblock">
<div class="content">
<img src="/2022/11/dowo_0102.png" alt="Smaller, more frequent releases">
</div>
<div class="title">Figure 3. Smaller releases, release often, faster feedback</div>
</div>
</div>
<div class="sect2">
<h3 id="_software_configuration_management">Software Configuration Management</h3>
<div class="paragraph">
<p>For our purposes we will take a narrower view of software configuration management (CM) and focus on the recommended software engineering practice of separating dynamic configuration from static runtime software. Doing so allows developers and operations engineers to change the configuration without having to rebuild the runtime such as might occur when deploying to different environments. Containers, based as they are on immutable images, amplify this behavior as the alternative would be configuration layered across multiple images for each deployment scenario.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deployment_patterns">Deployment Patterns</h3>
<div class="paragraph">
<p>Aligned with the goal of automation across all steps in the software delivery lifecycle are patterns for deployment. We look here for strategies that can balance across criteria including safety, testability, reversibility, and downtime minimization in cloud-scale scenarios. Some deployment patterns also offer opportunities for capturing and responding to feedback. An A/B deployment allows for testing a user-defined hypothesis such as whether application version A is more effective than B. Usage results can then drive weighted load balancing across the alternatives. Automation of deployment strategies in this DevOps world are implemented by driving the orchestration APIs.</p>
</div>
</div>
<div class="sect2">
<h3 id="_continuous_improvement">Continuous Improvement</h3>
<div class="paragraph">
<p>Let&#8217;s conclude this chapter by covering continuous improvement (<a href="#one_3">Continuous improvement</a>), which should be the thread that connects all of the process improvement&#x2013;related practices summarized. The environment changes and so must we. These practices make it easy and inexpensive to experiment, formulate, and test hypotheses, as well as capture, act on, and experiment with the feedback received. This way we can continue to inject energy into the system and so maintain a state of dynamic stability&#x2014;a balance of adaptive/agile versus fixed/stable.</p>
</div>
<div id="one_3" class="imageblock">
<div class="content">
<img src="/2022/11/dowo_0103.png" alt="Continuous Improvement">
</div>
<div class="title">Figure 4. Continuous improvement</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary">Summary</h3>
<div class="paragraph">
<p>We covered here some of what is unique and nuanced about DevOps with OpenShift and why it matters. Realizing these DevOps concepts using natively container-aware automation can bring cloud deployment power to <em>all</em> the people, from 10x programmer to citizen developer. The following chapters will show you how.</p>
</div>
</div>
</div>
</div></p>
                <p><a href="2022/11/devops-with-openshift-5yr.html#disqus_thread">Commentaires</a></p>
            

        
            
                <a href="../2022/11/the-compelling-platform.html"><h1>The Compelling Platform</h1></a>
                <p>01 November 2022</p>

                <p>Tags :
                <a href="platform.html">platform</a>, <a href="platform as product.html">platform as product</a>, <a href="openshift.html">openshift</a>
                </p>

                <!--a href="https://twitter.com/share" class="twitter-share-button" data-url="http://www.eformat.me/2022/11/the-compelling-platform.html" data-text="The Compelling Platform" data-via="eformat" data-lang="en">Tweeter</a-->
                <!--script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script-->
                <div class="g-plusone" data-size="medium" data-href="http://www.eformat.me/2022/11/the-compelling-platform.html"></div>

                <p><h1><a href="#the-compelling-platform" id="the-compelling-platform">The Compelling Platform</a></h1>
<p><em>&ldquo;Build it and they will come !&rdquo;</em> - 1989 movie Field of Dreams.</p>
<p>A <em>key</em> ingredient for success when building a platform is that it must be <em>compelling</em> to use. What makes a platform compelling ?</p>
<ul>
<li>The platform is self-service for the overwhelming majority of use cases.</li>
<li>The platform is composable, containing discrete services that can be used independently.</li>
<li>The platform does not force an inflexible way of working upon the delivery team.</li>
<li>The platform is quick and cheap to start using, with an easy on-ramp (e.g. Quick start guides, documentation, code samples)</li>
<li>The platform has a rich internal user community for sharing</li>
<li>The platform is secure and compliant by default</li>
<li>The platform is up to date</li>
<li>The platform is the thinnest viable</li>
</ul>
<p>A platform should also be more than just software and APIs - it is documentation, and consulting, and support and evangelism, and templates and guidelines.</p>
<p>You must also move away from <em>project</em> as the primary mechanism for funding and staffing delivery of technology. Platform is a <em>product</em>, and needs a long-lived and stable team tasked with both build and run.</p>
<h2><a href="#define-platform" id="define-platform">Define Platform</a></h2>
<p><em>&ldquo;A platform is a curated experience for the customer of the platform (engineers)&rdquo;</em> - Matthew Skelton.</p>
<p><em>&ldquo;A digital platform is a foundation of self-service APIs, tools, services, knowledge and support which are arranged as a compelling internal product. Autonomous delivery teams can make use of the platform to deliver product features at a higher pace, with reduced co-ordination.&rdquo;</em> - Evan Botcher.</p>
<p>What it is <b>NOT:</b></p>
<ul>
<li>It is not the limited virtualised hosting and locked-down centrally-managed tooling that you already have.</li>
<li>It is not just OpenShift, Ansible or RHEL by themselves.</li>
<li>The <em>fattest</em> platform in the world.</li>
</ul>
<p>The starting point is to <em>&ldquo;Use these N services in these ways &hellip;&rdquo;</em> - this is a curated experience.</p>
<p>The <em>Thinnest Viable Platform</em> is a small, curated set of complementary services or patterns used together to simplify and accelerate delivery.</p>
<p>The platform will evolve and its design should meet common team interaction modes.</p>
<p><a href="https://github.com/eformat/the-compelling-platform/blob/main/PATTERNS.md">Patterns for the Compelling Platform &gt;</a></p>
</p>
                <p><a href="2022/11/the-compelling-platform.html#disqus_thread">Commentaires</a></p>
            

        

    </div>

    <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
        <div class="sidebar-module sidebar-module-inset">
            <h4>Mike Hepburn</h4>
            <p>This is really working out great.</p>
            <ul>
                <li><a href="https://twitter.com/eformat">@eformat</a></li>
            </ul>
        </div>


        <div class="sidebar-module">
            <h4>Tags</h4>
            <ol class="list-unstyled" style="margin-left: 0px">
                

                <li><a href="openshift.html">openshift</a> (8)</li>
                

                <li><a href="gitops.html">gitops</a> (3)</li>
                

                <li><a href="aiml.html">aiml</a> (2)</li>
                

                <li><a href="argocd.html">argocd</a> (2)</li>
                

                <li><a href="gpu.html">gpu</a> (2)</li>
                

                <li><a href="java.html">java</a> (2)</li>
                

                <li><a href="stable diffusion.html">stable diffusion</a> (2)</li>
                

                <li><a href="acm.html">acm</a> (1)</li>
                

                <li><a href="aws.html">aws</a> (1)</li>
                

                <li><a href="bgp.html">bgp</a> (1)</li>
                

                <li><a href="bird.html">bird</a> (1)</li>
                

                <li><a href="constraints.html">constraints</a> (1)</li>
                

                <li><a href="cost.html">cost</a> (1)</li>
                

                <li><a href="devops.html">devops</a> (1)</li>
                

                <li><a href="disconnected.html">disconnected</a> (1)</li>
                

                <li><a href="fediverse.html">fediverse</a> (1)</li>
                

                <li><a href="fedora.html">fedora</a> (1)</li>
                

                <li><a href="flink.html">flink</a> (1)</li>
                

                <li><a href="frr.html">frr</a> (1)</li>
                

                <li><a href="mastodon.html">mastodon</a> (1)</li>
                

                <li><a href="metallb.html">metallb</a> (1)</li>
                

                <li><a href="optaplanner.html">optaplanner</a> (1)</li>
                

                <li><a href="patterns.html">patterns</a> (1)</li>
                

                <li><a href="platform.html">platform</a> (1)</li>
                

                <li><a href="platform as product.html">platform as product</a> (1)</li>
                

                <li><a href="pulsar.html">pulsar</a> (1)</li>
                

                <li><a href="quarkus.html">quarkus</a> (1)</li>
                

                <li><a href="registries.html">registries</a> (1)</li>
                

                <li><a href="security.html">security</a> (1)</li>
                

                <li><a href="sno.html">sno</a> (1)</li>
                

                <li><a href="social.html">social</a> (1)</li>
                

                <li><a href="streaming.html">streaming</a> (1)</li>
                

                <li><a href="vault.html">vault</a> (1)</li>
                
            </ol>
        </div>
    </div>

    </div>

		</div>
		<div id="push"></div>
    </div>
    
    <div id="footer">
      <div class="container">
        <p class="text-muted credit">Blog posts are published under Creative Commons license by-nc-sa <em>Creative Commons by-nc-sa</em>. <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"/></a></p>
        <p class="text-muted credit">&copy; 2023 | Baked with <a href="http://jbake.org">JBake v2.7.0-rc.6</a><a href="https://github.com/eformat/blog.eformat.me/actions"> | Published Sun May 07 00:09:05 UTC 2023</a></p>
      </div>
    </div>
    
    <!-- Javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../js/lightbox.js"></script>

    <!--script type="text/javascript">
        window.___gcfg = {lang: 'en'};

        (function() {
            var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
            po.src = 'https://apis.google.com/js/platform.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
        })();
    </script-->

    <!--script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-', '');
      ga('send', 'pageview');

    </script-->
    
  </body>
</html>

